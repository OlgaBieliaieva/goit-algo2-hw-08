# Алгоритми оптимізації та керування ресурсами


## Завдання 1. 
### Оптимізація доступу до даних за допомогою LRU-кешу


Реалізуйте програму, що демонструє, як LRU-кеш пришвидшує багаторазові «гарячі» запити до великого масиву чисел.


#### Технічні умови

1. Маємо масив array довжиною N зі строго додатних цілих чисел (1 ≤ N ≤ 100 000). Необхідно обробити Q запитів (1 ≤ Q ≤ 50 000) двох типів

    - Range(L, R) — обчислити суму елементів array[L : R + 1].
    - Update(index, value) — присвоїти array[index] ← value.


2. Реалізуйте чотири функції

    - range_sum_no_cache(array, left, right) — повертає суму без кешування.
    - update_no_cache(array, index, value) — оновлює елемент без кешування.
    - range_sum_with_cache(array, left, right) — виконує пошук у готовому класі LRUCache (ємність K = 1000). Якщо cache.get() повертає −1 (cache-miss), обчислює суму, зберігає її методом put() і повертає результат.
    - update_with_cache(array, index, value) — оновлює масив і видаляє всі діапазони з кешу, що містять змінений index. Інвалідація здійснюється лінійним проходом по ключах кешу — іншої модифікації класу не потрібно.


3. Для тестування використайте таку функцію для генерації масиву запитів:

```Python
import random

def make_queries(n, q, hot_pool=30, p_hot=0.95, p_update=0.03):
    hot = [(random.randint(0, n//2), random.randint(n//2, n-1))
           for _ in range(hot_pool)]
    queries = []
    for _ in range(q):
        if random.random() < p_update:        # ~3% запитів — Update
            idx = random.randint(0, n-1)
            val = random.randint(1, 100)
            queries.append(("Update", idx, val))
        else:                                 # ~97% — Range
            if random.random() < p_hot:       # 95% — «гарячі» діапазони
                left, right = random.choice(hot)
            else:                             # 5% — випадкові діапазони
                left = random.randint(0, n-1)
                right = random.randint(left, n-1)
            queries.append(("Range", left, right))
    return queries

```

Ця функція створює список із 50 000 запитів до масиву з 100 000 елементів. 
Три відсотки — це оновлення окремих елементів, решта — запити на підрахунок суми. 
Для більшості таких Range-запитів (95 %) обирається один із тридцяти заздалегідь випадково визначених «гарячих» діапазонів, 
тобто вони багаторазово повторюються протягом тесту. 
Решта запитів (5 %) формуються повністю випадковим чином.

Така модель максимально наближена до реальних сценаріїв із популярними й рідкісними діапазонами, 
що дозволяє оцінити користь кешу саме в умовах повторюваного доступу.


#### Пояснення параметрів:

- n — розмір масиву, для цього завдання використовуйте n = 100_000.

- q — кількість запитів у тесті, для цього завдання використовуйте q = 50_000.

- hot_pool — кількість «гарячих» (часто використовуваних) діапазонів, тобто тих відрізків, до яких запити будуть надходити найчастіше. За замовчуванням 30.

- p_hot — ймовірність, що новий запит типу Range буде взято саме з цього «гарячого» пулу. У нашій моделі це 95 %, тобто практично всі Range-запити дублюють популярні діапазони.

- p_update — частка запитів, які є оновленням значення елемента. У нашому прикладі 3 % (решта 97 % — це запити на суму).


4. Виміряйте час виконання всієї послідовності запитів двічі — без кешу та з кешем — і виведіть результати у зрозумілому текстовому вигляді, наприклад.


#### Критерії прийняття
1. Усі функції: range_sum_no_cache, update_no_cache, range_sum_with_cache, update_with_cache — реалізовані та працюють.
2. Програма вимірює час виконання запитів з кешем і без нього та виводить результати у зрозумілому вигляді.
3. Результати тестування представлені у зручному для розуміння форматі, щоб можна було оцінити ефективність використання LRU-кешу.
4. Код виконується без помилок і відповідає технічним вимогам.


#### Приклад виведення в термінал виконання програми

```Python

Без кешу :  12.06 c
LRU-кеш  :   4.71 c  (прискорення ×2.6)

```


#### Рішення

1. Підготовка даних

- Генерується масив array довжиною n = 100_000 зі випадкових чисел 1–100.

- Функція make_queries() створює q = 50_000 запитів двох типів:

- Range(L, R) — обчислення суми діапазону.

- Update(index, value) — оновлення значення елемента.

- 95 % Range-запитів беруться з «гарячих» діапазонів (30 часто використовуваних), решта — випадкові.

2. Реалізація без кешу

- range_sum_no_cache(array, left, right) обчислює суму кожного разу.

- update_no_cache(array, index, value) змінює елемент масиву.

- Такий підхід точний, але повільний для повторюваних діапазонів.

3. Реалізація з LRU-кешем

- Використовується LRUCache на основі двозв’язного списку + хеш-таблиці (ємність 1000).

- range_sum_with_cache(array, left, right, cache)

    - Якщо результат є в кеші, повертає його (cache-hit).

    - Інакше обчислює суму, зберігає в кеш і повертає (cache-miss).

- update_with_cache(array, index, value, cache)

    - Оновлює масив.

    - Інвалідує всі діапазони в кеші, що містять змінений індекс.

4. Тестування та порівняння

- Виконується послідовність всіх запитів двічі: без кешу та з кешем.

- Час вимірюється через time.time().

- Виводиться прискорення виконання за рахунок кешу.

5. Приклад результату

|Метод |Час виконання (сек.) |Прискорення |
|-------------------------------|-------------------|------------|
|Без кешу |8.31 |— |
|LRU-кеш (ємність 1000) |3.10 |×2.68 |

- LRU-кеш ефективно прискорює багаторазові «гарячі» запити.

- Інвалідація при оновленні гарантує коректність результатів.

---

## Завдання 2. 
### Реалізація Rate Limiter з використанням алгоритму Sliding Window для обмеження частоти повідомлень у чаті


У чат-системі необхідно реалізувати механізм обмеження частоти повідомлень від користувачів для запобігання спаму. 
Реалізація повинна використовувати алгоритм Sliding Window для точного контролю часових інтервалів, 
який дозволяє відстежувати кількість повідомлень у заданому часовому вікні й обмежувати користувачів у надсиланні повідомлень, якщо ліміт перевищено.


#### Технічні умови

1. Реалізація повинна використовувати алгоритм Sliding Window для точного контролю часових інтервалів.

2. Базові параметри системи: розмір вікна (window_size) — 10 секунд і максимальна кількість повідомлень у вікні (max_requests) — 1.

3. Реалізуйте клас SlidingWindowRateLimiter.

4. Реалізуйте методи класу:

   - _cleanup_window — для очищення застарілих запитів з вікна та оновлення активного часового вікна;
   - can_send_message — для перевірки можливості відправлення повідомлення в поточному часовому вікні;
   - record_message — для запису нового повідомлення й оновлення історії користувача;
   - time_until_next_allowed — для розрахунку часу очікування до можливості відправлення наступного повідомлення.

5. Структура даних для зберігання історії повідомлень — collections.deque.


#### Критерії прийняття
1. При спробі відправити повідомлення раніше ніж через 10 секунд повертається методом can_send_message значення False.

2. При першому повідомленні від користувача завжди повертається True.

3. При видаленні всіх повідомлень з вікна користувача видаляється запис про користувача зі структури даних.

4. Метод time_until_next_allowed повертає час очікування в секундах.

5. Тестова функція згідно з прикладом прогнана й працює відповідно до очікувань.


##### Шаблон завдання
```Python

import random
from typing import Dict
import time
from collections import deque

class SlidingWindowRateLimiter:
    def __init__(self, window_size: int = 10, max_requests: int = 1):
				pass
    def _cleanup_window(self, user_id: str, current_time: float) -> None:
        pass

    def can_send_message(self, user_id: str) -> bool:
        pass

    def record_message(self, user_id: str) -> bool:
        pass

    def time_until_next_allowed(self, user_id: str) -> float:
        pass

# Демонстрація роботи
def test_rate_limiter():
    # Створюємо rate limiter: вікно 10 секунд, 1 повідомлення
    limiter = SlidingWindowRateLimiter(window_size=10, max_requests=1)

    # Симулюємо потік повідомлень від користувачів (послідовні ID від 1 до 20)
    print("\\n=== Симуляція потоку повідомлень ===")
    for message_id in range(1, 11):
        # Симулюємо різних користувачів (ID від 1 до 5)
        user_id = message_id % 5 + 1

        result = limiter.record_message(str(user_id))
        wait_time = limiter.time_until_next_allowed(str(user_id))

        print(f"Повідомлення {message_id:2d} | Користувач {user_id} | "
              f"{'✓' if result else f'× (очікування {wait_time:.1f}с)'}")

        # Невелика затримка між повідомленнями для реалістичності
        # Випадкова затримка від 0.1 до 1 секунди
        time.sleep(random.uniform(0.1, 1.0))

    # Чекаємо, поки вікно очиститься
    print("\\nОчікуємо 4 секунди...")
    time.sleep(4)

    print("\\n=== Нова серія повідомлень після очікування ===")
    for message_id in range(11, 21):
        user_id = message_id % 5 + 1
        result = limiter.record_message(str(user_id))
        wait_time = limiter.time_until_next_allowed(str(user_id))
        print(f"Повідомлення {message_id:2d} | Користувач {user_id} | "
              f"{'✓' if result else f'× (очікування {wait_time:.1f}с)'}")
        # Випадкова затримка від 0.1 до 1 секунди
        time.sleep(random.uniform(0.1, 1.0))

if __name__ == "__main__":
    test_rate_limiter()

```

##### Очікуване виведення
```Python

=== Симуляція потоку повідомлень ===
Повідомлення  1 | Користувач 2 | ✓
Повідомлення  2 | Користувач 3 | ✓
Повідомлення  3 | Користувач 4 | ✓
Повідомлення  4 | Користувач 5 | ✓
Повідомлення  5 | Користувач 1 | ✓
Повідомлення  6 | Користувач 2 | × (очікування 7.0с)
Повідомлення  7 | Користувач 3 | × (очікування 6.5с)
Повідомлення  8 | Користувач 4 | × (очікування 7.0с)
Повідомлення  9 | Користувач 5 | × (очікування 6.8с)
Повідомлення 10 | Користувач 1 | × (очікування 7.4с)

Очікуємо 4 секунди...

=== Нова серія повідомлень після очікування ===
Повідомлення 11 | Користувач 2 | × (очікування 1.0с)
Повідомлення 12 | Користувач 3 | × (очікування 0.7с)
Повідомлення 13 | Користувач 4 | × (очікування 0.4с)
Повідомлення 14 | Користувач 5 | × (очікування 0.0с)
Повідомлення 15 | Користувач 1 | ✓
Повідомлення 16 | Користувач 2 | ✓
Повідомлення 17 | Користувач 3 | ✓
Повідомлення 18 | Користувач 4 | ✓
Повідомлення 19 | Користувач 5 | ✓
Повідомлення 20 | Користувач 1 | × (очікування 7.0с)

```

#### Рішення

1. Ідея Sliding Window

- Для кожного користувача зберігається deque з часовими мітками повідомлень.

- Вікно часу має розмір window_size (10 секунд).

- Алгоритм видаляє старі повідомлення, що вийшли за межі вікна, і перевіряє, чи не перевищено ліміт max_requests (1 повідомлення).

2. Методи класу

- _cleanup_window(user_id, current_time) — очищує старі повідомлення з вікна; видаляє користувача, якщо повідомлень не залишилося.

- can_send_message(user_id) — перевіряє, чи можна надіслати повідомлення; перше повідомлення завжди дозволено.

- record_message(user_id) — записує повідомлення, якщо дозволено, і повертає True/False.

- time_until_next_allowed(user_id) — повертає час очікування у секундах до наступного дозволеного повідомлення.

3. Структура даних

- Використовується collections.deque для швидкого видалення старих повідомлень зліва (O(1)).

- Для кожного користувача зберігається окрема черга повідомлень.

4. Тестування

- Симулюється потік повідомлень від користувачів з ID від 1 до 5.

- Виводиться результат надсилання повідомлення та час очікування до наступного дозволеного.

- Після очікування 4 секунди надходить нова серія повідомлень, що демонструє роботу алгоритму.

5. Очікуваний результат

- Перше повідомлення кожного користувача завжди дозволене.

- Наступні повідомлення у межах 10 секунд блокуються (False), метод time_until_next_allowed показує залишок часу до дозволу.

- Після видалення старих повідомлень користувач автоматично видаляється зі структури даних.